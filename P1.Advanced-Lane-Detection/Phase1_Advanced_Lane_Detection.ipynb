{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Phase1_Advanced_Lane_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmed192a/ImageProcessing-PatternRecognition/blob/main/P1.Advanced-Lane-Detection/Phase1_Advanced_Lane_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase one: Lane Detection\n",
        "**In this first phase**, the goal is to write a software pipeline to identify the lane boundaries in a video from a front-facing camera on a car. itâ€™s required to find and track the lane lines and the\n",
        "position of the car from the center of the lane. <br>\n",
        "As a bonus, track the radius of curvature of the road too.\n",
        "\n",
        "Assume the camera is mounted at the center of the car, such that the lane center is the midpoint at the bottom of the image between the two lines you've detected. \n",
        "\n",
        "The offset of the lane center from the center of the image (converted from pixels to meters) is your distance from the center of the lane."
      ],
      "metadata": {
        "id": "2uxC7E_vZLi7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "krgTM9UXamaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "E9_2f4OBdeP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Line Class\n"
      ],
      "metadata": {
        "id": "DPJY1o_hbR-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LaneLines:\n",
        "    def __init__(self):\n",
        "        self.left_fit = None\n",
        "        self.right_fit = None\n",
        "        self.binary = None\n",
        "        self.nonzero = None\n",
        "        self.nonzerox = None\n",
        "        self.nonzeroy = None\n",
        "        self.clear_visibility = True\n",
        "        self.dir = []\n",
        "    \n",
        "        # HYPERPARAMETERS\n",
        "        # Number of sliding windows\n",
        "        self.nwindows = 9\n",
        "        # Width of the the windows +/- margin\n",
        "        self.margin = 100\n",
        "        # Mininum number of pixels found to recenter window\n",
        "        self.minpix = 50\n",
        "    \n",
        "    def forward(self, img):\n",
        "        self.extract_features(img)\n",
        "        return self.fit_poly(img)\n",
        "\n",
        "    def fit_poly(self, img):\n",
        "        out = np.dstack((img, img, img))\n",
        "        leftx, lefty, rightx, righty, out_img = self.find_lane_pixels(img)\n",
        "\n",
        "        if len(lefty) > 1500:\n",
        "            self.left_fit = np.polyfit(lefty, leftx, 2)\n",
        "        if len(righty) > 1500:\n",
        "            self.right_fit = np.polyfit(righty, rightx, 2)\n",
        "\n",
        "        # Generate x and y values for plotting\n",
        "        maxy = img.shape[0] - 1\n",
        "        miny = img.shape[0] // 3\n",
        "        if len(lefty):\n",
        "            maxy = max(maxy, np.max(lefty))\n",
        "            miny = min(miny, np.min(lefty))\n",
        "\n",
        "        if len(righty):\n",
        "            maxy = max(maxy, np.max(righty))\n",
        "            miny = min(miny, np.min(righty))\n",
        "\n",
        "        ploty = np.linspace(miny, maxy, img.shape[0])\n",
        "\n",
        "        left_fitx = self.left_fit[0]*ploty**2 + self.left_fit[1]*ploty + self.left_fit[2]\n",
        "        right_fitx = self.right_fit[0]*ploty**2 + self.right_fit[1]*ploty + self.right_fit[2]\n",
        "\n",
        "        # Visualization\n",
        "        c = 0\n",
        "        for i, y in enumerate(ploty):\n",
        "            c = c+1\n",
        "            if(c == 2):\n",
        "                yo = int(y)\n",
        "                lo = int(l)\n",
        "                ro = int(r)\n",
        "            y = int(ploty[i])\n",
        "            l = int(left_fitx[i])\n",
        "            r = int(right_fitx[i])\n",
        "            cv2.line(out, (l, y), (r, y), (0, 255, 0),20)\n",
        "            if(c == 100):\n",
        "                c = 0\n",
        "                cv2.line(out,(lo,yo),(l,y), (255,0,0), 50)\n",
        "                cv2.line(out,(ro,yo),(r,y), (255,0,0), 50)\n",
        "\n",
        "        return out, out_img\n",
        "\n",
        "    def extract_features(self, img):\n",
        "        self.img = img\n",
        "        # Height of of windows - based on nwindows and image shape\n",
        "        self.window_height = np.int(img.shape[0]//self.nwindows)\n",
        "    \n",
        "        # Identify the x and y positions of all nonzero pixel in the image\n",
        "        self.nonzero = img.nonzero()\n",
        "        \n",
        "        self.nonzerox = np.array(self.nonzero[1])\n",
        "        self.nonzeroy = np.array(self.nonzero[0])\n",
        "\n",
        "    def find_lane_pixels(self, img):\n",
        "        assert(len(img.shape) == 2)\n",
        "\n",
        "        # Create an output image to draw on and visualize the result\n",
        "        out_img = np.dstack((img, img, img))\n",
        "\n",
        "        bottom_half = img[img.shape[0]//2:,:]\n",
        "        histogram =  np.sum(bottom_half, axis=0)\n",
        "\n",
        "        midpoint = histogram.shape[0]//2\n",
        "        leftx_base = np.argmax(histogram[:midpoint])\n",
        "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
        "\n",
        "        # Current position to be update later for each window in nwindows\n",
        "        leftx_current = leftx_base\n",
        "        rightx_current = rightx_base\n",
        "        y_current = img.shape[0] + self.window_height//2\n",
        "\n",
        "        # Create empty lists to reveice left and right lane pixel\n",
        "        leftx, lefty, rightx, righty = [], [], [], []\n",
        "\n",
        "        # Step through the windows one by one\n",
        "        for window in range(self.nwindows):\n",
        "            # Identify window boundaries in x and y (and right and left)\n",
        "            win_y_low = img.shape[0] - (window+1)*self.window_height\n",
        "            win_y_high = img.shape[0] - window*self.window_height\n",
        "            win_xleft_low = leftx_current - self.margin\n",
        "            win_xleft_high = leftx_current +self. margin\n",
        "            win_xright_low = rightx_current - self.margin\n",
        "            win_xright_high = rightx_current + self.margin\n",
        "\n",
        "            # Draw the windows on the visualization image\n",
        "            cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),\n",
        "            (0,255,0), 2) \n",
        "            cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),\n",
        "            (0,255,0), 2) \n",
        "\n",
        "            y_current -= self.window_height\n",
        "            center_left = (leftx_current, y_current)\n",
        "            center_right = (rightx_current, y_current)\n",
        "\n",
        "            good_left_x, good_left_y = self.pixels_in_window(center_left, self.margin, self.window_height)\n",
        "            good_right_x, good_right_y = self.pixels_in_window(center_right, self.margin, self.window_height)\n",
        "\n",
        "            # Append these indices to the lists\n",
        "            leftx.extend(good_left_x)\n",
        "            lefty.extend(good_left_y)\n",
        "            rightx.extend(good_right_x)\n",
        "            righty.extend(good_right_y)\n",
        "\n",
        "            if len(good_left_x) > self.minpix:\n",
        "                leftx_current = np.int32(np.mean(good_left_x))\n",
        "            if len(good_right_x) > self.minpix:\n",
        "                rightx_current = np.int32(np.mean(good_right_x))\n",
        "\n",
        "        return leftx, lefty, rightx, righty, out_img\n",
        "\n",
        "    def pixels_in_window(self, center, margin, height):\n",
        "        topleft = (center[0]-margin, center[1]-height//2)\n",
        "        bottomright = (center[0]+margin, center[1]+height//2)\n",
        "    \n",
        "        condx = (topleft[0] <= self.nonzerox) & (self.nonzerox <= bottomright[0])\n",
        "        condy = (topleft[1] <= self.nonzeroy) & (self.nonzeroy <= bottomright[1])\n",
        "        return self.nonzerox[condx&condy], self.nonzeroy[condx&condy]\n",
        "\n",
        "    def measure_curvature(self):\n",
        "        ym = 30/720\n",
        "        xm = 3.7/700\n",
        "\n",
        "        left_fit = self.left_fit.copy()\n",
        "        right_fit = self.right_fit.copy()\n",
        "        y_eval = 700 * ym\n",
        "\n",
        "        # Compute R_curve (radius of curvature)\n",
        "        left_curveR =  ((1 + (2*left_fit[0] *y_eval + left_fit[1])**2)**1.5)  / np.absolute(2*left_fit[0])\n",
        "        right_curveR = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
        "\n",
        "        xl = np.dot(self.left_fit, [700**2, 700, 1])\n",
        "        xr = np.dot(self.right_fit, [700**2, 700, 1])\n",
        "        pos = (1280//2 - (xl+xr)//2)*xm\n",
        "        return left_curveR, right_curveR, pos"
      ],
      "metadata": {
        "id": "pvadeHSGddni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prespective Transform Class\n"
      ],
      "metadata": {
        "id": "Z-sKhZh6c5TJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PerspectiveTransformation:\n",
        "    def __init__(self):\n",
        "        \"\"\"Init PerspectiveTransformation.\"\"\"\n",
        "        self.src = np.float32([(550, 460),     # top-left\n",
        "                               (150, 720),     # bottom-left\n",
        "                               (1200, 720),    # bottom-right\n",
        "                               (770, 460)])    # top-right\n",
        "        self.dst = np.float32([(100, 0),\n",
        "                               (100, 720),\n",
        "                               (1100, 720),\n",
        "                               (1100, 0)])\n",
        "        self.M = cv2.getPerspectiveTransform(self.src, self.dst)\n",
        "        self.M_inv = cv2.getPerspectiveTransform(self.dst, self.src)"
      ],
      "metadata": {
        "id": "mZbLN_IrddEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Globale Var\n"
      ],
      "metadata": {
        "id": "QGpuiQKFc9SV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xXNmGlHOdcpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Blend Frames\n"
      ],
      "metadata": {
        "id": "mA078IXXdBLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DBUDEtuVdb71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Threshold methods\n"
      ],
      "metadata": {
        "id": "KAnNjoN3dGzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kDCBWg7XdbQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process Frame Pipeline\n"
      ],
      "metadata": {
        "id": "y42-o01odJkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-5zLJO9rdapg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Code\n"
      ],
      "metadata": {
        "id": "1ws29kgddVZ0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7VkvBenZEaz"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}